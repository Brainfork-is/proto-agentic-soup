# Global/common
NODE_ENV=development
LLM_PROVIDER=auto  # auto, vertex, local

# Google Vertex AI (optional)
GOOGLE_CLOUD_PROJECT=
GOOGLE_CLOUD_LOCATION=us-central1
GOOGLE_APPLICATION_CREDENTIALS=
# Or GOOGLE_CLOUD_CREDENTIALS for base64 encoded credentials
LLM_MAX_TOKENS_PER_HOUR=100000
LLM_MAX_TOKENS_PER_AGENT=1000

# Local LLM via Ollama (optional)
LOCAL_LLM_ENABLED=0  # Set to 1 to enable
LOCAL_MODEL_PATH=granite3.1-dense:8b
LOCAL_LLM_ENDPOINT=http://localhost:11434/api/generate
LOCAL_LLM_MAX_TOKENS_PER_HOUR=200000
LOCAL_LLM_MAX_TOKENS_PER_AGENT=2000

# Services ports
SOUP_RUNNER_PORT=3000
BROWSER_GATEWAY_PORT=3100
SITE_KB_PORT=3200

# Browser gateway
ALLOWED_HOSTS=localhost,127.0.0.1,*.local,*.example.com

# MCP Knowledge Server (optional)
# MCP_KNOWLEDGE_SERVER=http://localhost:8080
# MCP_BEARER_TOKEN=your-bearer-token-here

# Runner (queues, db, costs)
REDIS_URL=redis://localhost:6379
DATABASE_URL=file:./dev.db
JOBS_PER_MIN=10
EPOCH_MINUTES=120
FAIL_PENALTY=3
BROWSER_STEP_COST=1

# Bootstrap mode for soup-runner (skip Redis/Prisma)
SOUP_BOOTSTRAP=1
